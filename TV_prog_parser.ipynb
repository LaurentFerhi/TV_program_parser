{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:14<00:00,  3.24it/s]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datetime import date\n",
    "\n",
    "def find_element(element, block, class_type, name):\n",
    "    try:\n",
    "        return element.find(block,{class_type: name}).getText().replace('\\n','').replace('  ','')\n",
    "    except AttributeError:\n",
    "        return ''\n",
    "\n",
    "def get_content(soup):\n",
    "    data = {}\n",
    "    idy = 0\n",
    "\n",
    "    for element in tqdm(soup.find_all('div',{'class': 'mainBroadcastCard-infos'})):\n",
    "        info = {}\n",
    "        # Starting hour\n",
    "        info['heure'] = find_element(element, 'div', 'class', 'mainBroadcastCard-startingHour')\n",
    "        # Title\n",
    "        info['titre'] = find_element(element, 'h3', 'class', 'mainBroadcastCard-title')\n",
    "        # Subtitle\n",
    "        info['sous_titre'] = find_element(element, 'div', 'class', 'mainBroadcastCard-subtitle')\n",
    "        # Type\n",
    "        info['type'] = find_element(element, 'div', 'class', 'mainBroadcastCard-type')\n",
    "        # Duration\n",
    "        info['duree'] = find_element(element, 'span', 'class', 'mainBroadcastCard-durationContent')\n",
    "        # Duration\n",
    "        info['new'] = find_element(element, 'div', 'class', 'mainBroadcastCard-new')\n",
    "        # Duration\n",
    "        info['live'] = find_element(element, 'div', 'class', 'mainBroadcastCard-live')\n",
    "        # Duration\n",
    "        info['rebroadcast'] = find_element(element, 'div', 'class', 'mainBroadcastCard-rebroadcast')\n",
    "\n",
    "        # Description\n",
    "        links = element.find('h3',{'class': 'mainBroadcastCard-title'})\n",
    "        for a in links.find_all('a', href=True): \n",
    "            if a.text: \n",
    "                desc_url = a['href']\n",
    "        soup_desc = bs4.BeautifulSoup(requests.get(desc_url).text,'html.parser')\n",
    "        \n",
    "        try:\n",
    "            info['description'] = soup_desc.find(\n",
    "                'p',\n",
    "                {'class','synopsis-twoPart resume'}).getText().replace('\\n','').replace('Lire la suite','')\n",
    "        except AttributeError:\n",
    "            info['description'] ='Aucune description'\n",
    "            \n",
    "        # Overview\n",
    "        info['genre'] = find_element(soup_desc, 'div', 'class', 'overview-overviewSubtitle')\n",
    "        \n",
    "        # Summary (casting)\n",
    "        if info['type'] == 'Cinéma':\n",
    "            try:\n",
    "                info['casting'] = soup_desc.find(\"meta\",  property='og:description')['content'].split('...')[0]\n",
    "            except AttributeError:\n",
    "                info['casting'] =''   \n",
    "        else:\n",
    "            info['casting'] ='' \n",
    "        \n",
    "        # insert into data\n",
    "        data[idy] = info\n",
    "        idy += 1\n",
    "\n",
    "    ### Find and clean channels\n",
    "    chaines = []\n",
    "    for element in soup.find_all('h2',{'class': 'homeGrid-cardsChannelName'}):\n",
    "        full_txt = element.getText().replace('\\n','').replace('  ','')\n",
    "        sr_only = element.find('span',{'class': 'sr-only'}).getText().replace('\\n','').replace('  ','')\n",
    "        for _ in range(2): # 2 evening time slots\n",
    "            chaines.append(full_txt.replace(sr_only,'')) \n",
    "            \n",
    "    ### Find images\n",
    "    img_link = []\n",
    "    for element in soup.find_all('div',{'class': 'pictureTagGenerator pictureTagGenerator-ratio-5-7'}):\n",
    "        if element.find('img')['src'].startswith('https'):\n",
    "            img_link.append(element.find('img')['src'])\n",
    "        elif element.find('img')['data-src'].startswith('https'):\n",
    "            img_link.append(element.find('img')['data-src'])\n",
    "        else:\n",
    "            img_link.append('no image')\n",
    "    # Cut list at length of channel list\n",
    "    img_link = img_link[:len(chaines)]\n",
    "    \n",
    "    ### create and clean dataframe\n",
    "    df = pd.DataFrame(data).T\n",
    "\n",
    "    # append channels and images\n",
    "    df['chaines'] = chaines\n",
    "    df['images'] = img_link\n",
    "\n",
    "    # merge broadcast columns\n",
    "    df['diffusion'] = df.apply(lambda x: x['new']+x['live']+x['rebroadcast'],axis=1)\n",
    "    df.drop(['new','live','rebroadcast'],axis=1,inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def generate_report(df):\n",
    "    with open('Programme.html','w',encoding='utf-8') as f:\n",
    "        # header and internal css\n",
    "        f.write('<!DOCTYPE html>\\n<html>\\n<head>\\n<meta charset=\"UTF-8\">\\n \\\n",
    "            <meta http-equiv=\"Content-Language\" content=\"fr-FR\" />\\n \\\n",
    "            <style> \\\n",
    "                body {font-family: Arial; background-color: #EEEEEE;}\\n \\\n",
    "                h1 {color: #311B92;}\\n \\\n",
    "                h2 {color: #0D47A1;}\\n \\\n",
    "                h3 {color: #2196F3;}\\n \\\n",
    "                img {border-radius: 5px;}\\n \\\n",
    "            </style>\\n \\\n",
    "            <title>Programme TV</title>\\n</head>\\n')\n",
    "        # body\n",
    "        f.write('<body>\\n<div>\\n')\n",
    "        f.write('<h1>Programme TV du {}</h1>\\n'.format(date.today().strftime(\"%d/%m/%Y\")))\n",
    "        channel = ''\n",
    "        for idx in list(df.index):\n",
    "            extract = df.iloc[idx]\n",
    "            # write channel\n",
    "            if extract['chaines'] != channel:\n",
    "                channel = extract['chaines']\n",
    "                f.write('<hr>\\n<h2>{}</h2>\\n'.format(channel))\n",
    "            # write main info\n",
    "            f.write('<h3>{} - {} - {}</h3>\\n'.format(\n",
    "                extract['heure'],\n",
    "                extract['titre'],\n",
    "                extract['sous_titre'],\n",
    "            ))\n",
    "            \n",
    "            # add image\n",
    "            f.write('<img src=\"{}\" alt=\"image\" />\\n'.format(extract['images']))\n",
    "            \n",
    "            # write meta\n",
    "            f.write('<p><em>{} - {} - {} - {} - {}</em></p>\\n'.format(\n",
    "                extract['type'],\n",
    "                extract['duree'],\n",
    "                extract['diffusion'],\n",
    "                extract['genre'],\n",
    "                extract['casting'],\n",
    "            ))\n",
    "            \n",
    "            # write desc\n",
    "            f.write('<p>{}</p>\\n'.format(\n",
    "                extract['description'],\n",
    "            ))\n",
    "        # eof\n",
    "        f.write('</div>\\n</body>\\n</html>')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    url = 'https://www.programme-tv.net/'\n",
    "    page = requests.get(url)\n",
    "    soup = bs4.BeautifulSoup(page.text,'html.parser')\n",
    "\n",
    "    df = get_content(soup)\n",
    "    generate_report(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
